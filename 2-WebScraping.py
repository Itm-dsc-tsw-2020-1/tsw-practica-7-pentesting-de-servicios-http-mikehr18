import sys
import requests as req
from bs4 import BeautifulSoup
import mysql.connector as mysql


def Scrap(host):
    try:
        url = req.get('http://'+ str(host))        
        if str(url.status_code) == "200":
            print("Conexion exitosa con: "+ host)
            s = BeautifulSoup(url.text, 'html.parser')
            print("Etiquetas de formularios (FORM): ")
            print(s.form)
            print("links encontrados: ")
            arr = s.find_all('a')
            i = 0
            for a in arr:
                print(a['href'])
                cursor.execute("INSERT INTO links (direccion) VALUES ('"+a['href']+"')")
                conexion.commit()
                i=+1
        else:
            print("No se pudo hacer conexi√≥n con: "+ host)

    except:
        print("Unexpected error:", sys.exc_info()[0])
        

def links(host):
    try:
        if "http://" in host or "https://" in host :
            url = req.get(str(host))
        else:
            url = req.get('http://'+ str(host))                    
        if str(url.status_code) == "200":
            print("Conexion a: "+ host)
            s = BeautifulSoup(url.text, 'html.parser')
            print("Etiquetas FORM encontradas: ")
            print(s.form)
        else:
            print("Fallo la conexion con: "+ host)    
    except:
        print("Unexpected error:", sys.exc_info()[0])
        

conexion = mysql.connect( 
    host='localhost',
    user= 'root',
    passwd='',
    db='nmap' )
cursor = conexion.cursor()
cursor.execute(  "select ip from host where servicio = 'http';") 
for ip in cursor.fetchall() :
    Scrap(ip[0]) 
cursor.execute( "SELECT direccion FROM links;")
for direccion in cursor.fetchall() :
    links(direccion[0]) 
conexion.close()